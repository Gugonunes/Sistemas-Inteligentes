{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm7mgPLdo7y1",
        "outputId": "09b371d0-245a-46be-8a54-ceef0a82570d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhores hiperparâmetros: {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "Treinamento - MSE: 0.06633323463562492, R²: 0.9563831480834202\n",
            "Teste - MSE: 0.23746970554563201, R²: 0.8441844304727919\n",
            "Possível overfitting detectado.\n",
            "R² Cross-Validated Score: 0.8077789908023847\n",
            "95% Confidence Interval for R²: (0.45193691901810096, 1.1636210625866683)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Escolha uma base de dados qualquer do site kaggle.com, tarefa de classificação\n",
        "o arquivo é o Student_performance_data_.csv\n",
        "\n",
        "Escolha um classificador do tipo ensamble\n",
        "\n",
        "Rode o classificador na base de dados e estime a performace de generalização\n",
        "\n",
        "Use método de hold-out para avaliação do modelo (treino/teste)\n",
        "\n",
        "Use método 10-fold para seleção do modelo (treino validação)\n",
        "\n",
        "Selecione o melhor modelo (hyperparâmetros) usando gridsearch\n",
        "\n",
        "Utilizando o modelo selecionado, avalie se existe overfitting\n",
        "\n",
        "Calcule intervalos de confiança via aproximação normal\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('Student_performance_data_.csv')\n",
        "\n",
        "# preprocessamento\n",
        "data = data.dropna()\n",
        "data = pd.get_dummies(data)\n",
        "\n",
        "# Separar os dados em conjuntos de treino e teste (método hold-out)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Definir o modelo de Random Forest\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Selecionar o melhor modelo (hiperparâmetros) usando GridSearchCV com validação cruzada 10-fold\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=10, scoring='r2', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Melhor modelo encontrado pelo GridSearchCV\n",
        "best_rf = grid_search.best_estimator_\n",
        "print(\"Melhores hiperparâmetros:\", grid_search.best_params_)\n",
        "\n",
        "# Avaliar o modelo no conjunto de teste para verificar overfitting\n",
        "y_train_pred = best_rf.predict(X_train)\n",
        "y_test_pred = best_rf.predict(X_test)\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(f'Treinamento - MSE: {mse_train}, R²: {r2_train}')\n",
        "print(f'Teste - MSE: {mse_test}, R²: {r2_test}')\n",
        "\n",
        "# Verificar se há overfitting comparando a performance no treino e no teste\n",
        "if r2_train > r2_test:\n",
        "    print(\"Possível overfitting detectado.\")\n",
        "\n",
        "# Calcular intervalos de confiança via aproximação normal\n",
        "scores = cross_val_score(best_rf, X, y, cv=10, scoring='r2')\n",
        "mean_score = np.mean(scores)\n",
        "std_dev = np.std(scores)\n",
        "\n",
        "confidence_interval = stats.norm.interval(0.95, loc=mean_score, scale=std_dev/np.sqrt(len(scores)))\n",
        "\n",
        "print(f'R² Cross-Validated Score: {mean_score}')\n",
        "print(f'95% Confidence Interval for R²: {confidence_interval}')\n"
      ]
    }
  ]
}